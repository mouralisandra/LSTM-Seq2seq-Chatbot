{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "31196d32",
   "metadata": {
    "id": "31196d32"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers , activations , models , preprocessing\n",
    "from tensorflow.keras import preprocessing , utils\n",
    "from gensim.models import Word2Vec\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d6c5c256",
   "metadata": {
    "id": "d6c5c256"
   },
   "outputs": [],
   "source": [
    "lines = open('data/movie_lines.txt',  encoding='utf-8', errors ='ignore').read().split('\\n')\n",
    "conversations_lines = open('data/movie_conversations.txt',  encoding='utf-8', errors ='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "a73eb1e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a73eb1e6",
    "outputId": "2614c878-b39e-476b-91e4-500f3181c819"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!',\n",
       " 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!',\n",
       " 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.',\n",
       " 'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?',\n",
       " \"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\"]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "33804dc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33804dc6",
    "outputId": "35b59a30-f5ce-4096-8765-a750d68b3d6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\"]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "621473e5",
   "metadata": {
    "id": "621473e5"
   },
   "outputs": [],
   "source": [
    "# Créer un dictionnaire avec une clé = id et une valeur = texte.\n",
    "id2line = {}\n",
    "for line in lines:\n",
    "    _line = line.split(' +++$+++ ')\n",
    "    if len(_line) == 5:\n",
    "        id2line[_line[0]] = _line[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "fd6fbf58",
   "metadata": {
    "id": "fd6fbf58"
   },
   "outputs": [],
   "source": [
    "# Créer une liste de toutes les lignes des conversations sous forme d'une liste de listes. a list of all conversations' lines\n",
    "conversations = [ ]\n",
    "for line in conversations_lines:\n",
    "    _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "    conversations.append(_line.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "863affa3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "863affa3",
    "outputId": "fbc11450-13ec-45fa-866c-e366bdf86452"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['L194', 'L195', 'L196', 'L197'],\n",
       " ['L198', 'L199'],\n",
       " ['L200', 'L201', 'L202', 'L203'],\n",
       " ['L204', 'L205', 'L206'],\n",
       " ['L207', 'L208']]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "f194d4aa",
   "metadata": {
    "id": "f194d4aa"
   },
   "outputs": [],
   "source": [
    "#Trier les lignes en textes d'entrée et textes de sortie.nputs = []\n",
    "outputs = []\n",
    "\n",
    "for conversation in conversations:\n",
    "    for i in range(len(conversation)-1):\n",
    "        inputs.append(id2line[conversation[i]])\n",
    "        outputs.append(id2line[conversation[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "502bd36e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "502bd36e",
    "outputId": "4cb4d167-9dca-4479-dfbd-0035e6e0f21e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
      "Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "\n",
      "Well, I thought we'd start with pronunciation, if that's okay with you.\n",
      "Not the hacking and gagging and spitting part.  Please.\n",
      "\n",
      "Not the hacking and gagging and spitting part.  Please.\n",
      "Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
      "\n",
      "You're asking me out.  That's so cute. What's your name again?\n",
      "Forget it.\n",
      "\n",
      "No, no, it's my fault -- we didn't have a proper introduction ---\n",
      "Cameron.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Charger quelques paires de textes d'entrée-sortie triées.\n",
    "for i in range(5):\n",
    "    print(inputs[i])\n",
    "    print(outputs[i]+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "387419a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "387419a6",
    "outputId": "082d134b-3302-46ac-c53e-43a1bae8f2c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994544\n",
      "221616\n"
     ]
    }
   ],
   "source": [
    "print(len(inputs))\n",
    "print(len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "e0065099",
   "metadata": {
    "id": "e0065099"
   },
   "outputs": [],
   "source": [
    "# changer le word format et supprimer charactères non necessaires\n",
    "def clean_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "5cc0d568",
   "metadata": {
    "id": "5cc0d568"
   },
   "outputs": [],
   "source": [
    "# Nettoyer les données\n",
    "clean_inputs = []\n",
    "for text in inputs:\n",
    "    clean_inputs.append(clean_text(text))\n",
    "    \n",
    "clean_outputs = []    \n",
    "for text in outputs:\n",
    "    clean_outputs.append(clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6821c0f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6821c0f0",
    "outputId": "5aa004de-0f5a-45eb-c9a0-fdac86ae142e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can we make this quick  roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad  again\n",
      "well i thought we would start with pronunciation if that is okay with you\n",
      "\n",
      "well i thought we would start with pronunciation if that is okay with you\n",
      "not the hacking and gagging and spitting part  please\n",
      "\n",
      "not the hacking and gagging and spitting part  please\n",
      "okay then how about we try out some french cuisine  saturday  night\n",
      "\n",
      "you are asking me out  that is so cute that is your name again\n",
      "forget it\n",
      "\n",
      "no no it is my fault  we did not have a proper introduction \n",
      "cameron\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Charger quelques paires de textes d'entrée-sortie triées.\n",
    "for i in range(5):\n",
    "    print(clean_inputs[i])\n",
    "    print(clean_outputs[i]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "99d3b05a",
   "metadata": {
    "id": "99d3b05a"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[340], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(text\u001b[39m.\u001b[39msplit()) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m min_line_length \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(text\u001b[39m.\u001b[39msplit()) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m max_line_length:\n\u001b[0;32m     12\u001b[0m         short_inputs_temp\u001b[39m.\u001b[39mappend(text)\n\u001b[1;32m---> 13\u001b[0m         short_outputs_temp\u001b[39m.\u001b[39mappend(clean_outputs[i])\n\u001b[0;32m     14\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39m# filter out the output texts that are too short/long\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# remove input and output texts that are shorter than 2 words and longer than 8 words.\n",
    "min_line_length = 2\n",
    "max_line_length = 4\n",
    "\n",
    "# filter out the input texts that are too short/long\n",
    "short_inputs_temp = []\n",
    "short_outputs_temp = []\n",
    "\n",
    "i = 0\n",
    "for text in clean_inputs:\n",
    "    if len(text.split()) >= min_line_length and len(text.split()) <= max_line_length:\n",
    "        short_inputs_temp.append(text)\n",
    "        short_outputs_temp.append(clean_outputs[i])\n",
    "    i += 1\n",
    "\n",
    "# filter out the output texts that are too short/long\n",
    "short_inputs = []\n",
    "short_outputs = []\n",
    "\n",
    "i = 0\n",
    "for text in short_outputs_temp:\n",
    "    if len(text.split()) >= min_line_length and len(text.split()) <= max_line_length:\n",
    "        short_outputs.append(text)\n",
    "        short_inputs.append(short_inputs_temp[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefcdd91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fefcdd91",
    "outputId": "03a04a71-63db-4f79-b420-fcb20de378db",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of questions: 12682\n",
      "# of answers: 12682\n",
      "% of data used: 50.0%\n"
     ]
    }
   ],
   "source": [
    "# Comparaison du nombre de lignes que nous allons utiliser avec le nombre total de lignes.\n",
    "print('# of questions:', len(short_inputs))\n",
    "print('# of answers:', len(short_outputs))\n",
    "print('% of data used: {}%'.format(round(len(short_inputs)/len(inputs),1)*500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff41f42",
   "metadata": {
    "id": "4ff41f42"
   },
   "outputs": [],
   "source": [
    "# add the end of sentence token to the end of every output.\n",
    "# add the go token to the beginning of every output.\n",
    "for i in range(len(short_outputs)):\n",
    "    short_outputs[i] = '<GO>'+short_outputs[i]+' <EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee157ee9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee157ee9",
    "outputId": "a425f185-564b-4332-d1e4-a085f75b7e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 7786\n"
     ]
    }
   ],
   "source": [
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(short_inputs + short_outputs)\n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
    "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4111c8c1",
   "metadata": {
    "id": "4111c8c1"
   },
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for word in tokenizer.word_index:\n",
    "    vocab.append(word)\n",
    "\n",
    "def tokenize(sentences):\n",
    "    tokens_list = []\n",
    "    vocabulary = []\n",
    "    for sentence in sentences:\n",
    "        tokens = sentence.split()\n",
    "        vocabulary += tokens\n",
    "        tokens_list.append(tokens)\n",
    "    return tokens_list, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e548bac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e548bac",
    "outputId": "53a9d7ad-c5cb-44cf-81fb-9dccc508f0b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12682, 6) 6\n"
     ]
    }
   ],
   "source": [
    "# encoder_input_data\n",
    "tokenized_inputs = tokenizer.texts_to_sequences(short_inputs)\n",
    "max_len_in = max([len(x) for x in tokenized_inputs])\n",
    "padded_inputs = preprocessing.sequence.pad_sequences(tokenized_inputs, maxlen=max_len_in, padding='post')\n",
    "encoder_input_data = np.array(padded_inputs)\n",
    "print(encoder_input_data.shape, max_len_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d15a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb8d15a9",
    "outputId": "eddddace-bf3d-400a-c89d-cb9329872011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12682, 9) 9\n"
     ]
    }
   ],
   "source": [
    "# decoder_input_data\n",
    "tokenized_outputs = tokenizer.texts_to_sequences(short_outputs)\n",
    "max_len_out = max([len(x) for x in tokenized_outputs])\n",
    "padded_outputs = preprocessing.sequence.pad_sequences(tokenized_outputs, maxlen=max_len_out, padding='post')\n",
    "decoder_input_data = np.array(padded_outputs)\n",
    "print(decoder_input_data.shape, max_len_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168bff8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b168bff8",
    "outputId": "eb8b7355-714c-49b2-8b1b-7c404ea45584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12682, 9, 7786)\n"
     ]
    }
   ],
   "source": [
    "# decoder_output_data\n",
    "tokenized_outputs = tokenizer.texts_to_sequences(short_outputs)\n",
    "for i in range(len(tokenized_outputs)) :\n",
    "    tokenized_outputs[i] = tokenized_outputs[i][1:-1]\n",
    "padded_outputs = preprocessing.sequence.pad_sequences(tokenized_outputs, maxlen=max_len_out, padding='post')\n",
    "onehot_outputs = utils.to_categorical(padded_outputs ,VOCAB_SIZE)\n",
    "decoder_output_data = np.array(onehot_outputs)\n",
    "print(decoder_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nyg0G-cjDDgc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyg0G-cjDDgc",
    "outputId": "aedf8eb1-3438-4730-cd00-e34075629dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)          [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_14 (Embedding)       (None, 6, 200)       1557200     ['input_31[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_15 (Embedding)       (None, 9, 200)       1557200     ['input_32[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_14 (LSTM)                 [(None, 200),        320800      ['embedding_14[0][0]']           \n",
      "                                 (None, 200),                                                     \n",
      "                                 (None, 200)]                                                     \n",
      "                                                                                                  \n",
      " lstm_15 (LSTM)                 [(None, 9, 200),     320800      ['embedding_15[0][0]',           \n",
      "                                 (None, 200),                     'lstm_14[0][1]',                \n",
      "                                 (None, 200)]                     'lstm_14[0][2]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 9, 7786)      1564986     ['lstm_15[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,320,986\n",
      "Trainable params: 5,320,986\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=(max_len_in , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( max_len_out ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15605348",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15605348",
    "outputId": "f53b0750-2611-488d-ec39-b7df4ffaf6fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "318/318 [==============================] - 31s 80ms/step - loss: 4.5837 - accuracy: 0.4063\n",
      "Epoch 2/15\n",
      "318/318 [==============================] - 24s 77ms/step - loss: 3.9673 - accuracy: 0.4280\n",
      "Epoch 3/15\n",
      "318/318 [==============================] - 24s 77ms/step - loss: 3.8665 - accuracy: 0.4360\n",
      "Epoch 4/15\n",
      "318/318 [==============================] - 25s 80ms/step - loss: 3.8034 - accuracy: 0.4440\n",
      "Epoch 5/15\n",
      "318/318 [==============================] - 25s 79ms/step - loss: 3.7505 - accuracy: 0.4469\n",
      "Epoch 6/15\n",
      "318/318 [==============================] - 25s 78ms/step - loss: 3.7057 - accuracy: 0.4519\n",
      "Epoch 7/15\n",
      "318/318 [==============================] - 25s 80ms/step - loss: 3.6648 - accuracy: 0.4539\n",
      "Epoch 8/15\n",
      "318/318 [==============================] - 23s 72ms/step - loss: 3.6226 - accuracy: 0.4564\n",
      "Epoch 9/15\n",
      "318/318 [==============================] - 24s 76ms/step - loss: 3.5843 - accuracy: 0.4590\n",
      "Epoch 10/15\n",
      "318/318 [==============================] - 23s 74ms/step - loss: 3.5479 - accuracy: 0.4610\n",
      "Epoch 11/15\n",
      "318/318 [==============================] - 24s 75ms/step - loss: 3.5160 - accuracy: 0.4642\n",
      "Epoch 12/15\n",
      "318/318 [==============================] - 23s 72ms/step - loss: 3.4835 - accuracy: 0.4669\n",
      "Epoch 13/15\n",
      "318/318 [==============================] - 22s 70ms/step - loss: 3.4527 - accuracy: 0.4692\n",
      "Epoch 14/15\n",
      "318/318 [==============================] - 22s 69ms/step - loss: 3.4243 - accuracy: 0.4713\n",
      "Epoch 15/15\n",
      "318/318 [==============================] - 23s 72ms/step - loss: 3.3964 - accuracy: 0.4736\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=100, epochs=10, validation_split=0.2)\n",
    "model.save( 'model.h5' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c85ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "5e0c85ce",
    "outputId": "26e5a188-5621-42d2-b06b-f6547d8781c5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = model.history.history['accuracy']\n",
    "loss = model.history.history['loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'g')\n",
    "plt.plot(epochs, loss, 'b')\n",
    "plt.legend(['Accuracy','Loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df2d2c",
   "metadata": {
    "id": "52df2d2c"
   },
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab02a92",
   "metadata": {
    "id": "eab02a92"
   },
   "outputs": [],
   "source": [
    "def str_to_tokens( sentence : str ):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    for word in words:\n",
    "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=max_len_in , padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af9797",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "id": "f8af9797",
    "outputId": "fbe1ee5d-d4db-48a3-ea4c-524bce730884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 718ms/step\n",
      "1/1 [==============================] - 1s 739ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " good night little little little little little little little little\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      " i am not little little little little little little little\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'dumbass'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[224], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m enc_model , dec_model \u001b[39m=\u001b[39m make_inference_models()\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     states_values \u001b[39m=\u001b[39m enc_model\u001b[39m.\u001b[39mpredict( str_to_tokens( \u001b[39minput\u001b[39;49m( \u001b[39m'\u001b[39;49m\u001b[39mEnter question : \u001b[39;49m\u001b[39m'\u001b[39;49m ) ) )\n\u001b[0;32m      5\u001b[0m     empty_target_seq \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros( ( \u001b[39m1\u001b[39m , \u001b[39m1\u001b[39m ) )\n\u001b[0;32m      6\u001b[0m     empty_target_seq[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mword_index[\u001b[39m'\u001b[39m\u001b[39mgo\u001b[39m\u001b[39m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[223], line 5\u001b[0m, in \u001b[0;36mstr_to_tokens\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      3\u001b[0m tokens_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words:\n\u001b[1;32m----> 5\u001b[0m     tokens_list\u001b[39m.\u001b[39mappend( tokenizer\u001b[39m.\u001b[39;49mword_index[ word ] ) \n\u001b[0;32m      6\u001b[0m \u001b[39mreturn\u001b[39;00m preprocessing\u001b[39m.\u001b[39msequence\u001b[39m.\u001b[39mpad_sequences( [tokens_list] , maxlen\u001b[39m=\u001b[39mmax_len_in , padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'dumbass'"
     ]
    }
   ],
   "source": [
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "for _ in range(10):\n",
    "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index['go']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        for word , index in tokenizer.word_index.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += ' {}'.format( word )\n",
    "                sampled_word = word\n",
    "        \n",
    "        if sampled_word == 'eos' or len(decoded_translation.split()) > max_len_out:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "\n",
    "    print( decoded_translation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88acdfae",
   "metadata": {
    "id": "88acdfae"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
